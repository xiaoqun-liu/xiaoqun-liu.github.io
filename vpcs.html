<!DOCTYPE html>
<html>

<!-- <body>
    <h1 style="color: grey; font-size: 36px; text-align: center; margin-top: 50px;">Seeking a potential advisor as I
        plan to apply for a Ph.D. program</h1>
</body> -->

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>VPCs</title>

    <!-- favicon -->
    <!-- <link href="favicon.png" rel=icon> -->

    <!-- web-fonts -->
    <link href="https://fonts.googleapis.com/css?family=Hind:300,400,500,600,700" rel="stylesheet">

    <!-- font-awesome -->
    <link href="css/font-awesome.min.css" rel="stylesheet">

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Style CSS -->
    <link href="css/style.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body id="page-top" data-spy="scroll" data-target=".navbar">
    <header class="page-header sticky-top">
        <div class="container">
            <a href="index.html" class="btn btn-header">Homepage</a>
        </div>
        <div class="container">
        </div>
    </header>

    <div id="main-wrapper">
        <!-- Page Preloader -->
        <div id="preloader">
            <div id="status">
                <div class="status-mes"></div>
            </div>
        </div>
        <div class="columns-block container">

            <!-- left -->
            <div class="left-col-block blocks" id="home">
                <header class="header theiaStickySidebar">
                    <div class="profile-img">
                        <img src="img/data.png" class="img-responsive" alt="" />
                    </div>
                    <div class="content">
                        <h1>Attention and Verbal Particle Constructions</h1>
                        <h3>Xiaoqun Liu, Steven Chu and John Idogun</h3>
                    </div>

                </header>
                <!-- .header-->
            </div>

            <!-- right -->
            <div class="right-col-block blocks">
                <div class="theiaStickySidebar">
           
                   

                    <!-- project -->
                    <section class="section-wrapper section-project gray-bg">
                        <div class="container-fluid" id="pro">
                            <div class="row">
                                <div class="col-md-12">
                                    <div class="section-title">
                                        Recent advancements in natural language processing (NLP), particularly with transformer-based models like those introduced by Vaswani et al.\cite{vaswani2017attention}, have significantly enhanced our ability to capture intricate linguistic dependencies. These models utilize attention mechanisms to effectively grasp long-range relationships between words in a sentence. However, verbs, being key components of sentence structure, often exhibit complexity beyond simple actions, especially when forming Verb-Particle Constructions (VPCs) such as "give up" or "throw out." These constructions incorporate additional verbal particles like "up" or "out," introducing further intricacy to the analysis.<br><br>

                                        Therefore, a crucial question arises: How do state-of-the-art auto-encoding and auto-regressive models handle VPCs within their attention mechanisms? Investigating how different models treat VPCs in terms of attention allocation can offer valuable insights into their understanding and processing of these linguistically nuanced structures. By delving into this aspect, we aim to shed light on the handling of VPCs by various NLP models, thereby advancing our understanding of their capabilities and limitations in processing complex linguistic phenomena.
                                    </div>
                                    <img src="img/poster.jpg" class="img-responsive" alt="" />
                                </div>
                            </div>
                        </div>
                        <!-- .container-fluid -->

                    </section>

                    <footer class="footer">
                        <div class="copyright-section">
                            <div class="container-fluid">
                                <div class="row">
                                    <div class="col-md-12">
                                        <div class="copytext">&copy; Resume. All rights reserved </div>
                                    </div>
                                </div>
                                <!--.row-->
                            </div>
                            <!-- .container-fluid -->
                        </div>
                        <!-- .copyright-section -->
                    </footer>
                    <!-- .footer -->
                </div>
                <!-- Sticky -->
            </div>
            <!-- .right-col-block -->
        </div>
        <!-- .columns-block -->
    </div>
    <!-- #main-wrapper -->

    <!-- jquery -->
    <script src="js/jquery-2.1.4.min.js"></script>

    <!-- Bootstrap -->
    <script src="js/bootstrap.min.js"></script>
    <script src="js/theia-sticky-sidebar.js"></script>
    <script src="js/scripts.js"></script>
</body>

</html>