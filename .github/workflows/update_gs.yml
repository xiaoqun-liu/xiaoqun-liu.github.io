name: Get Citation Data

on:
  page_build:
  schedule:
    - cron: '0 8 * * *'   # Morning 8 
  workflow_dispatch:       # 可手动触发

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r google_scholar_crawler/requirements.txt

      - name: Run crawler
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
          PYTHONUNBUFFERED: '1'    # insures real-time logging
        run: |
          set -euxo pipefail       # exit on error, print all commands
          cd google_scholar_crawler
          pwd; ls -al
          # set 600s timeout to avoid infinite hanging
          timeout 600s python3 -u main.py
          ls -al results || true   # list results folder

      # push results back to repo
      - name: Commit and Push results
        run: |
          git config user.name "${GITHUB_ACTOR}"
          git config user.email "xiaoqun.will@gmail.com"
          git add google_scholar_crawler/results/*.json
          git commit -m "Updated Citation Data" || echo "No changes to commit"
          git push origin main --force
