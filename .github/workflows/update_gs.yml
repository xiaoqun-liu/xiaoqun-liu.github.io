name: Get Citation Data

on:
  page_build:
  schedule:
    - cron: '0 8 * * *'
  workflow_dispatch:

permissions:
  contents: write   # push

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r google_scholar_crawler/requirements.txt

      - name: Run crawler
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
          PYTHONUNBUFFERED: '1'
        run: |
          set -euxo pipefail
          cd google_scholar_crawler
          pwd; ls -al
          timeout 600s python3 -u main.py
          echo "== results listing =="
          mkdir -p results
          ls -al results || true

      - name: Commit and Push results
        run: |
          set -euxo pipefail
          git rev-parse --abbrev-ref HEAD || true
          git remote -v

          git config user.name "${GITHUB_ACTOR}"
          git config user.email "xiaoqun.will@gmail.com"

          git add -f google_scholar_crawler/results/gs_data.json \
                   google_scholar_crawler/results/gs_data_shieldsio.json

          git status --short
          git commit -m "Updated Citation Data" || echo "No changes to commit"

          # rebase to avoid unnecessary merge commits
          git pull --rebase origin main || true
          git push origin main
