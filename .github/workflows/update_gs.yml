name: Get Citation Data

on:
  page_build:
  schedule:
    - cron: '0 8 * * *'   # 每天早上 8 点执行
  workflow_dispatch:       # 可手动触发

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      # 1️⃣ 拉取仓库
      - uses: actions/checkout@v4

      # 2️⃣ 设置 Python 环境
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      # 3️⃣ 安装依赖
      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install -r google_scholar_crawler/requirements.txt

      # 4️⃣ 运行爬虫
      - name: Run crawler
        env:
          GOOGLE_SCHOLAR_ID: ${{ secrets.GOOGLE_SCHOLAR_ID }}
          PYTHONUNBUFFERED: '1'    # 实时打印日志
        run: |
          set -euxo pipefail       # 遇错立即退出
          cd google_scholar_crawler
          pwd; ls -al
          # 运行 main.py，设置超时（600 秒 = 10 分钟）
          timeout 600s python3 -u main.py
          ls -al results || true   # 输出结果目录文件列表

      # 5️⃣ 提交与推送结果（在主仓库，不要再 git init）
      - name: Commit and Push results
        run: |
          git config user.name "${GITHUB_ACTOR}"
          git config user.email "xiaoqun.will@gmail.com"
          git add google_scholar_crawler/results/*.json
          git commit -m "Updated Citation Data" || echo "No changes to commit"
          git push origin google-scholar-stats --force
